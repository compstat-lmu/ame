---
title: Local Partial Dependence Regression example
author: 
  name: Bodo Burger
  affiliation: LMU Munich
date: 2018-07
output:
  html_document: 
    toc: yes
  github_document:
    toc: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = TRUE,
                      cache = TRUE, cache.path = "cache/",
                      fig.path = "figures/file-name-", fig.height = 4, fig.width = 5)
library("ggplot2")
library("mlr")
#library("ame")
devtools::load_all()

theme_set(theme_light())
set.seed(4218)

normalize = function(x, lower.bound = 0, upper.bound = 1) {
  x.min = min(x)
  c1 = (upper.bound - lower.bound)/(max(x) - x.min)
  c2 = lower.bound - c1 * x.min
  return(c1 * x + c2)
}
```

# Data generating process

```{r dgp,fig.width=6}
n = 200
x = runif(n, min = 0, max = 1)
x1 = x + rnorm(n, 0, 0.05)
x2 = x + rnorm(n, 0, 0.05)
x3 = normalize(0.9 * x + rnorm(n, 0, .1))
x4 = .85 * x + rnorm(n, 0, .1)
x5 = normalize(0.5 * x + rnorm(n, 0, .1))
y1 = function(x) x
y2 = function(x) 10*(x-.25)^2
y3 = function(x) -2 * x
y4 = function(x) 40 * ((x-.2)^3 - (x-.2)^2) + 4
y5 = function(x) -4 * cos(4*pi*x) * x + 4
x.grid = seq(0, 1, .01)
par(mfrow = c(2,3), oma = c(0, 0, 2, 0))
plot(x.grid, y1(x.grid), type = "l")
plot(x.grid, y2(x.grid), type = "l")
plot(x.grid, y3(x.grid), type = "l")
plot(x.grid, y4(x.grid), type = "l")
plot(x.grid, y5(x.grid), type = "l")
mtext("True partial effects", outer = TRUE, cex = 1.5)
y = y1(x1) + y2(x2) + y3(x3) + y4(x4) + y5(x5) + rnorm(n, 0, .1)
dt = data.frame(y, x1, x2, x3, x4, x5)
#y = y1(x1) + y5(x5) + rnorm(n, 0, .1)
#dt = data.frame(y, x1, x5)
knitr::kable(cor(dt))
```

# Models

We try linear model, neural net, SVM and (to cover a tree method) gradient boosting.

```{r fit-models}
tsk = makeRegrTask(data = dt, target = "y")
# linear model:
lm.lrn = makeLearner("regr.lm")
lm.mod = train(lm.lrn, tsk)
lm.mod$learner.model
# neural net:
nnet.lrn = makeLearner("regr.nnet", skip = FALSE, size = 20, decay = 0.0001, maxit = 1000,
  trace = FALSE)
nnet.mod = train(nnet.lrn, tsk)
# svm:
svm.lrn = makeLearner("regr.svm")
svm.mod = train(svm.lrn, tsk)
# tree method:
ntrees = 10000
gbm.lrn = makeLearner("regr.gbm", n.trees = ntrees, interaction.depth = 1, shrinkage = .02)
gbm.mod = train(gbm.lrn, tsk)
```

# LPD Linear Model

```{r,fig.width=9}
gridExtra::grid.arrange(
  plotLPD(computeLPD(lm.mod$learner.model, dt, "x1")) + ggtitle("LPD, l=20"),
    #scale_y_continuous(limits = c(-10,12)),
  plotLPD(computeLPD(lm.mod$learner.model, dt, "x1", l = 200)) + ggtitle("LPD, l = 200"),
  plotPartialDependence(generatePartialDependenceData(lm.mod, tsk, "x1", n = 30,
  individual = FALSE, derivative = FALSE)) + ggtitle("PD"),
ncol = 3)
```

LPD does not produce a straight line with slope equal to the coefficient of the linear model for low l.
For *l = nrow(data)* LPD equals PD.

```{r}
l = 20
gridExtra::grid.arrange(
  plotLPD(computeLPD(lm.mod$learner.model, dt, "x2", l = l)),
  plotLPD(computeLPD(lm.mod$learner.model, dt, "x3", l = l)),
  plotLPD(computeLPD(lm.mod$learner.model, dt, "x4", l = l)),
  plotLPD(computeLPD(lm.mod$learner.model, dt, "x5", l = l)),
  ncol = 2)

computeLPD(lm.mod$learner.model, dt, "x2", derivative = TRUE)$y.hat
```

# LPD neural net

```{r}
par(mfrow = c(1,1))
plotLPD(computeLPD(nnet.mod$learner.model, dt, "x5"))
plotLPD(computeWPD(nnet.mod$learner.model, dt, "x5"))
plotLPD(computeWPD(nnet.mod$learner.model, dt, "x5", wp = 1))
plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x5", n = 100, individual = FALSE))
plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x5", n = 10, individual = TRUE))

plotLPD(computeLPD(nnet.mod$learner.model, dt, "x4"))
plotLPD(computeWPD(nnet.mod$learner.model, dt, "x4", wp = 1))
plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x4", n = 100, individual = FALSE))
plot(seq(-.1, 1, .05), y4(seq(-.1, 1, .05)), type = "l")

plotLPD(computeLPD(nnet.mod$learner.model, dt, "x2"))
plotLPD(computeWPD(nnet.mod$learner.model, dt, "x2"))
plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x2", n = 20, individual = FALSE))
plot(seq(0, 1, .05), y2(seq(0, 1, .05)), type = "l")

plotLPD(computeLPD(nnet.mod$learner.model, dt, "x1"))
plotLPD(computeWPD(nnet.mod$learner.model, dt, "x1"))
plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x1", n = 100, individual = FALSE))
plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x1", n = 10, individual = TRUE))
plot(seq(0, 1, .05), y1(seq(0, 1, .05)), type = "l")

gridExtra::grid.arrange(
  plotPartialDependence(generatePartialDependenceData(nnet.mod, tsk, "x5", n = 50, derivative = TRUE)) +
    scale_y_continuous(limits = c(-45,35)) + ggtitle("Partial Deriv"),
  plotLPD(computeLPD(nnet.mod$learner.model, dt, "x5", n = 50, derivative = TRUE)) +
    scale_y_continuous(limits = c(-45,35)) + ggtitle("Local Partial Deriv"),
  ncol = 2)

generatePartialDependenceData(nnet.mod, tsk, "x5", n = 20, derivative = TRUE)
```

