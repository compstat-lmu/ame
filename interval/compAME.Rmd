---
title: Test AME implementation
author: 
  - name: Bodo Burger
date: 2018-06-06
output:
  html_document: 
    toc: yes
  github_document:
    toc: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = TRUE,
                      #cache = TRUE, cache.path = "cache/compAME/",
                      fig.path = "figures/compAME-")
library("ame")
library("ggplot2")
library("mlr")
theme_set(theme_light())
```

# Regression tasks (numeric target)

## numeric features

### (Roughly) Monotonic Relationship / Perceptible Trend

One numeric feature x, relationship to target y is "overall" monotonic / upward trend; furthermore non-linear,
non-convex and stochastic (i.e. we add noise).

```{r monotonic-dgp}
set.seed(123)
n = 100
target.fun = function(x) (sin(x) + 1) * x + .2 * cos(x + 1) + 2 * x
x1 = runif(n, 0, 6)
x2 = runif(n, 100, 1000) # this feature has no influence on y
eps = rnorm(n, 0, 1)
y.true = target.fun(x1)
y = y.true + eps
df = data.frame(x1, x2, y)

lm.mod = lm(y ~ ., data = df)
poly12.mod = lm(y ~ poly(x1, 12, raw = TRUE) + x2, data = df)
grid.x = data.frame(x1 = seq(0, 6, .01), x2 = mean(x2))
df.plot = data.frame(x1 = grid.x$x1, true = target.fun(grid.x$x1),
  fitlm = predict(lm.mod, newdata = grid.x),
  fitpoly12 = predict(object = poly12.mod, newdata = grid.x))
df.plot = reshape2::melt(df.plot, id.vars = "x1", variable.name = "type", value.name = "y")
ggplot(data = df.plot, mapping = aes(x = x1, y = y, col = type, group = type)) + geom_line() +
  geom_point(data = df, mapping = aes(x = x1, y = y), alpha = .3, inherit.aes = FALSE) +
  ggtitle("True relationship vs observed data vs predicted values")
```

```{r}
lm.mod
lm.ame = compAME(lm.mod, df, features = c("x1", "x2"))
poly12.ame = compAME(poly12.mod, df, c("x1", "x2"), parallel = TRUE)
lm.ame
poly12.ame
computeAME(lm.mod, data = df, c("x1", "x2"))
computeAME(poly12.mod, df, c("x1", "x2"))

regr.tsk = makeRegrTask(data = df, target = "y")
lm.lrn = makeLearner("regr.lm")
lm.mod.mlr = train(lm.lrn, regr.tsk)
lm.mod.mlr$learner.model

compAME(lm.mod.mlr, regr.tsk, c("x1", "x2"))

p1 = plotAME(lm.mod, df, lm.ame, "y") + ggtitle("linear model")
p2 = plotAME(poly12.mod, df, poly12.ame, "y") + ggtitle("poly12 model")
gridExtra::grid.arrange(p1, p2, nrow = 2)
```

The AME for the poly12 model is higher than for the lm model. Maybe the AME of poly12 is a more plausible value for the feature effect of x1 given the data?

```{r}
lm.coef = coef(lm.mod)
poly12.ame = compAME(poly12.mod, df, feature = "x1")
plotAME(poly12.ame, df, poly12.ame, "y") +
  geom_abline(mapping = aes(slope = lm.coef[2], intercept = lm.coef[1]), color = "green") +
  ggtitle("AME of lm and poly12")
```


### Non-monotonic Relationship / No Trend

```{r no-trend-dgp}
set.seed(1215)
n = 100
target.fun = function(x) 5 * sin(2 * x) + 2 * cos(x + 1)
x1 = runif(n, 0, 6)
x2 = runif(n, 100, 1000) # this feature has no influence on y
eps = rnorm(n, 0, 1)
y.true = target.fun(x1)
y = y.true + eps
df = data.frame(x1, x2, y)

lm.mod = lm(y ~ ., data = df)
poly12.mod = lm(y ~ poly(x1, 12, raw = TRUE) + x2, data = df)
grid.x = data.frame(x1 = seq(0, 6, .01), x2 = mean(x2))
df.plot = data.frame(x1 = grid.x$x1, true = target.fun(grid.x$x1),
  fitlm = predict(lm.mod, newdata = grid.x),
  fitpoly12 = predict(object = poly12.mod, newdata = grid.x))
df.plot = reshape2::melt(df.plot, id.vars = "x1", variable.name = "type", value.name = "y")
ggplot(data = df.plot, mapping = aes(x = x1, y = y, col = type, group = type)) + geom_line() +
  geom_point(data = df, mapping = aes(x = x1, y = y), alpha = .3, inherit.aes = FALSE) +
  ggtitle("True relationship vs observed data vs predicted values")
```

```{r}
lm.mod
lm.ame = compAME(lm.mod, df, c("x1", "x2"))
poly12.ame = compAME(poly12.mod, df, c("x1", "x2"))
lm.ame
poly12.ame

regr.tsk = makeRegrTask(data = df, target = "y")
lm.lrn = makeLearner("regr.lm")
lm.mod.mlr = train(lm.lrn, regr.tsk)
lm.mod.mlr$learner.model

p1 = plotAME(lm.mod, df, lm.ame, "y") + ggtitle("linear model")
p2 = plotAME(poly12.mod, df, poly12.ame, "y") + ggtitle("poly12 model")
gridExtra::grid.arrange(p1, p2, nrow = 2)
```

## many numeric features

Now let's look at a task with many numeric features.

```{r}

```

## "real" data

```{r}
df = getTaskData(fuelsubset.task)[ , 1:20]
knitr::kable(df[1:5, 1:6], digits = 4)
lm.mod = lm(heatan ~ ., data = df)
lm.coefs = coef(lm.mod)[-1]
lm.ame = compAME(lm.mod, df, features = names(df)[-1])
all.equal(lm.ame, lm.coefs)

fuel.tsk = makeRegrTask(data = df, target = "heatan")
lm.lrn = makeLearner("regr.lm")
lm.mod.mlr = train(lm.lrn, fuel.tsk)
summary(lm.mod.mlr$learner.model)
rf.lrn = makeLearner("regr.randomForest")
rf.mod.mlr = train(rf.lrn, fuel.tsk)
system.time(compAME(lm.mod.mlr, fuel.tsk, names(df)[-1], parallel = FALSE))
system.time(compAME(lm.mod.mlr, fuel.tsk, names(df)[-1], parallel = TRUE))
system.time(compAME(rf.mod.mlr, fuel.tsk, names(df)[-1], parallel = FALSE))
system.time(compAME(rf.mod.mlr, fuel.tsk, names(df)[-1], parallel = TRUE))
lm.ame.mlr = compAME(lm.mod.mlr, fuel.tsk, names(df)[-1])
all.equal(lm.ame, lm.ame.mlr)
lm.ame.mlr
compAME(rf.mod.mlr, fuel.tsk, names(df)[-1], parallel = TRUE)
```

## numeric and categorical features

```{r dgp-numeric-and-binary}
n = 10000
bin1 = rbinom(n, 1, prob = .75)
bin2 = (rbinom(n, 1, prob = .35) + 2) * 2
cat1.map = setNames(c(0,-2,2,6), c("blue", "red2", "red", "green"))
cat1 = sample(factor(cat1.map, labels = names(cat1.map)), n, replace = TRUE, prob = c(.25, .25, .25, .25))
ord1.map = setNames(c(0,4,5,10,20), c("low", "midlow", "mid", "midhi", "high"))
ord1 = sample(factor(ord1.map, labels = names(ord1.map)), n, replace = TRUE, prob = c(.1, .2, .2, .3, .2))
logic1 = sample(c(TRUE, FALSE), n, replace = TRUE, prob = c(.45, .55))
char1 = sample(c("A", "E", "I"), n, replace = TRUE, prob = c(.3, .4, .3))
x1 = runif(n, 0, 1)
x2 = runif(n, 0, 1)
x3 = rnorm(n, -1, 1)
x4 = runif(n, -.5, .5)
eps = rnorm(n, 0, 2)
# data generating process:
y = .4 + 2.3 * bin1 + 2.2 * x1 + bin2 * x2 + 3 * x2 + 1.7 * x3^2 + x4 +
  .1 * cat1.map[cat1] + .1 * ord1.map[ord1] + logic1 * 1.3 +
  ifelse(char1 == "A", 0, ifelse(char1 == "E", -1, 1)) + eps
df = data.frame(y, x1, x2, x3, x4, bin1 = factor(bin1), bin2 = factor(bin2), cat1, ord1, logic1, char1)
knitr::kable(head(df))
```

### Linear model

```{r}
#lm.mod = lm(y ~ x1 + x2 + x3 + I(x3^2) + x4, data = df)
lm.mod = lm(y ~ ., data = df)
summary(lm.mod)
computeAME(lm.mod, df, names(df)[-1])
compAME(lm.mod, df, names(df)[-1])
system.time(computeAME(lm.mod, df, names(df)[-1]))
system.time(compAME(lm.mod, df, names(df)[-1]))
system.time(compAME(lm.mod, df, names(df)[-1], parallel = TRUE))
```

```{r}
# data generating process without logic:
y = .4 + 2.3 * bin1 + 2.2 * x1 + bin2 * x2 + 3 * x2 + 1.7 * x3^2 + x4 +
  .1 * cat1.map[cat1] + .1 * ord1.map[ord1] +
  ifelse(char1 == "A", 0, ifelse(char1 == "E", -1, 1)) + eps
df = data.frame(y, x1, x2, x3, x4, bin1 = factor(bin1), bin2 = factor(bin2), cat1, ord1, char1)
knitr::kable(head(df))

regr.tsk = makeRegrTask(data = df, target = "y")
lm.lrn = makeLearner("regr.lm")
lm.mod.mlr = train(lm.lrn, regr.tsk)
lm.mod.mlr$learner.model
compAME(lm.mod.mlr, regr.tsk, names(df)[-1], parallel = TRUE)
system.time(compAME(lm.mod.mlr, regr.tsk, names(df)[-1], parallel = TRUE))
computeAME(lm.mod.mlr, df, names(df[-1]))
```



Performance of the linear model:

```{r}
lm.pred = predict(lm.mod.mlr, regr.tsk)
performance(lm.pred, list(mse, rsq, expvar))
```


### Random forest

```{r}
rf.lrn = makeLearner("regr.randomForest")
rf.mod.mlr = train(rf.lrn, regr.tsk)
rf.pred = predict(rf.mod.mlr, regr.tsk)
performance(rf.pred, list(mse, rsq, expvar))
compAME(rf.mod.mlr, regr.tsk, names(df)[-1])
# computeAME(rf.mod.mlr, df, "x1")
# computeAME(rf.mod.mlr, df, "bin1") #TODO: error
#   Type of predictors in new data do not match that of the training data.
```

Results of `compAME()` and `computeAME()` are the same for `numDeriv::grad(..., method = "simple"). Default method is Richardson extrapolation.

### Boosting

```{r}
gbm.lrn = makeLearner("regr.gbm", n.trees = 1000, interaction.depth = 20)
gbm.mod.mlr = train(gbm.lrn, regr.tsk)
gbm.pred = predict(gbm.mod.mlr, regr.tsk)
performance(gbm.pred, list(mse, rsq, expvar))
compAME(gbm.mod.mlr, regr.tsk, names(df)[-1])
computeAME(gbm.mod.mlr, df, names(df)[-1])
compAME(gbm.mod.mlr, regr.tsk, "bin1")
computeAME(gbm.mod.mlr, df, "bin1")
```

# Classification tasks

## Binary classification

### Logistic model

```{r}
spam.data = getTaskData(spam.task)
knitr::kable(spam.data[1:5, 52:58])

log.mod = glm(type ~ ., data = spam.data, family = binomial())
summary(log.mod)

log.lrn = makeLearner("classif.logreg", predict.type = "prob")
log.mod.mlr = train(log.lrn, spam.task)
summary(log.mod.mlr$learner.model)
log.pred = predict(log.mod.mlr, task = spam.task)
performance(log.pred, list(mmce))

1 - predict(log.mod, type = "response")[1:7]
getPredictionProbabilities(log.pred)[1:7]
all.equal(1 - unname(predict(log.mod, type = "response")), getPredictionProbabilities(log.pred))

features = c("remove", "edu", "charExclamation")
compAME(log.mod.mlr, spam.task, features)
compAME(log.mod, spam.data, features, predict.fun = function(object, newdata) predict(object, newdata = newdata, type = "response"))
compAME(log.mod, spam.data, features)
computeAME(log.mod.mlr, spam.data, features)
computeAME(log.mod, spam.data, features, predict.fun = function(object, newdata) predict(object, newdata = newdata, type = "response"))
```

Change positive class (`positive = "spam"`):

```{r}
spam.task.sp = makeClassifTask(data = spam.data, target = "type", positive = "spam")
log.mod.mlr.sp = train(log.lrn, spam.task.sp)
all.equal(log.mod.mlr$learner.model$coefficients, log.mod.mlr.sp$learner.model$coefficients)
log.pred.sp = predict(log.mod.mlr.sp, task = spam.task)
predict(log.mod, type = "response")[1:7] # positive class is class with higher level
getPredictionProbabilities(log.pred.sp)[1:7] # depends on positive class argument
```


```{r pdp-binary-classif}
log.pdp = generatePartialDependenceData(log.mod.mlr, spam.task, features)
plotPartialDependence(log.pdp) + ggtitle("Partial dependence for logistic regression (spam task)")
```

### Random Forest

```{r}
rf.lrn = makeLearner("classif.randomForest", predict.type = "prob")
rf.mod.mlr = train(rf.lrn, spam.task)
rf.pred = predict(rf.mod.mlr, spam.task)
performance(rf.pred, list(mmce))
compAME(rf.mod.mlr, regr.tsk, "x1")
computeAME(rf.mod.mlr, df, "x1")
compAME(rf.mod.mlr, regr.tsk, "bin1")
# computeAME(rf.mod.mlr, df, "bin1") #TODO: error
#   Type of predictors in new data do not match that of the training data.
```

### Boosting

```{r}
gbm.lrn = makeLearner("classif.gbm", predict.type = "prob", n.trees = 1000, interaction.depth = 20)
gbm.mod.mlr = train(gbm.lrn, spam.task)
gbm.pred = predict(gbm.mod.mlr, spam.task)
performance(gbm.pred, list(mmce))
compAME(gbm.mod.mlr, spam.task, features)
computeAME(gbm.mod.mlr, spam.data, features)
compAME(gbm.mod.mlr$learner.model, spam.data, features, predict.fun = function(object, newdata) predict(object, newdata = newdata, n.trees = 1000, type = "response"))
```

"Benchmark":
```{r}
system.time(compAME(gbm.mod.mlr, spam.task, features))
system.time(computeAME(gbm.mod.mlr, spam.data, features))
system.time(compAME(gbm.mod.mlr$learner.model, spam.data, features, predict.fun = function(object, newdata) predict(object, newdata = newdata, n.trees = 1000, type = "response")))
```


```{r pdp-binary-classif}
gbm.pdp = generatePartialDependenceData(gbm.mod.mlr, spam.task, features)
plotPartialDependence(gbm.pdp) + ggtitle("Partial dependence for gbm (spam task)")
```


## Multiclass

```{r}
str(iris)
knitr::kable(head(iris))


```


